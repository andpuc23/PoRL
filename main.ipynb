{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.train_env import Electric_Car\n",
    "from models.baseline import BaselineModel\n",
    "from models.baseline2 import BaselineModel2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models.tabular_qlearning import TabularQLearning\n",
    "from envs.feature_engineering import DataHelper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis():\n",
    "    data_path_train = 'data/train.xlsx'\n",
    "    df = pd.read_excel(data_path_train)\n",
    "\n",
    "    df['Month'] = df['PRICES'].dt.month\n",
    "    df['DayOfWeek'] = df['PRICES'].dt.dayofweek\n",
    "    df['AvgPerDay'] = df.iloc[:, 1:25].mean(axis=1)\n",
    "\n",
    "    monthly_avg = df.groupby('Month')['AvgPerDay'].mean()\n",
    "    day_of_week_avg = df.groupby('DayOfWeek')['AvgPerDay'].mean()\n",
    "    hourly_avg = df.iloc[:, 1:25].mean()\n",
    "\n",
    "    monthly_avg.plot(kind='bar', title='Average Price per Month',edgecolor='black')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Average Price')\n",
    "    plt.show()\n",
    "\n",
    "    day_of_week_avg.plot(kind='bar', title='Average Price per Day of the Week',edgecolor='black')\n",
    "    plt.xlabel('Day of the Week')\n",
    "    plt.ylabel('Average Price')\n",
    "    plt.show()\n",
    "\n",
    "    hourly_avg.plot(kind='bar', title='Average Price per Hour',edgecolor='black')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Average Price')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dh = DataHelper()\n",
    "\n",
    "# def learn(env, model):\n",
    "#     states, rewards, infos = [], [], []\n",
    "#     truncated = False\n",
    "#     terminated = False\n",
    "#     while(terminated == False and truncated == False):\n",
    "#         action = model.predict(env)\n",
    "#         obs, reward, termination, truncation, info = env.step(action)\n",
    "#         new_obs = dh.process_data(obs)\n",
    "\n",
    "#         states.append(new_obs)\n",
    "#         rewards.append(reward)\n",
    "#         terminated = termination\n",
    "#         truncated = truncation\n",
    "#         infos.append(info)\n",
    "\n",
    "#     return states, rewards, terminated, truncated, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         16.66666667 33.33333333         inf]\n",
      "[ 0.     22.0025 44.005  66.0075 88.01  ]\n",
      "[ 1.          4.83333333  8.66666667 12.5        16.33333333 20.16666667\n",
      "         inf]\n",
      "[0 5 7]\n",
      "[1.  3.2 5.4 7.6 9.8 inf]\n",
      "(3, 5, 6, 2, 3, 5)\n",
      "Please wait, the algorithm is learning! The current simulation is 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 4 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-46aa47622b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularQLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_Qtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulations_per_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madaptive_epsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapting_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#model.create_Q_table()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#model.load_Qtable('model_checkpoints/Tabular1.npy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project RL/PoRL/models/tabular_qlearning.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, simulations, simulations_per_avg, learning_rate, epsilon, epsilon_decay, adaptive_epsilon, adapting_learning_rate)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0midx_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mQ_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_vars_qtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mQ_target\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_vars_qtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 4 with size 3"
     ]
    }
   ],
   "source": [
    "data_path_train = 'data/train.xlsx'\n",
    "data_path_test = 'data/validate.xlsx'\n",
    "\n",
    "simulations = 5\n",
    "simulations_per_average = 1\n",
    "learning_rate = 0.1\n",
    "epsilon = 0.05\n",
    "epsilon_decay = simulations\n",
    "adaptive_epsilon = True\n",
    "adapting_learning_rate = False\n",
    "discount_rate = 0\n",
    "\n",
    "features_Qtable = [0, 1, 2, 3, 5] #battery, price, hour, day of week, month \n",
    "bin_size = [4, 6, 7, 3, 4, 5] #bin size of features + bin size of actions\n",
    "\n",
    "model = TabularQLearning(data_path_train, discount_rate, bin_size, features_Qtable)\n",
    "model.train(simulations, simulations_per_average, learning_rate, epsilon, epsilon_decay, adaptive_epsilon, adapting_learning_rate)\n",
    "#model.create_Q_table()\n",
    "#model.load_Qtable('model_checkpoints/Tabular1.npy')\n",
    "model.visualize_rewards_and_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_Qtable('test.npy')\n",
    "actions, rewards, states, infos = model.play(data_path_test, plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of entries', model.Qtable.size)\n",
    "print('Number of zeros', np.sum(model.Qtable==0))\n",
    "print('Revenue', sum(rewards))\n",
    "\n",
    "for i in range(len(features_Qtable)):\n",
    "    axes = list(range(len(features_Qtable)+1))\n",
    "    axes.remove(axes[i])\n",
    "    sums = np.sum(model.Qtable_updates, axis=tuple(axes))\n",
    "    print(sums)\n",
    "    plt.bar(range(len(sums)), sums, color='green', edgecolor='black')\n",
    "    plt.title('Sum of updates per cell of feature %d'%i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    #state : [battery_level, price, int(hour), int(day_of_week), int(day_of_year), int(month), int(year), int(self.car_is_available)]\n",
    "    print('\\nbattery',int(states[i][0]), '  price',int(states[i][1]), '  hour',int(states[i][2]), '  availability',int(states[i][-1]))\n",
    "    print('action',infos[i])\n",
    "    print('reward',rewards[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [0, 49, 50]\n",
    "f = np.linspace(0, 50, 5) #bin size=5, bins = 4\n",
    "0-10 1\n",
    "10-20 2\n",
    "...\n",
    "40-49.9999 4\n",
    "50.1 5\n",
    "\n",
    "q bin size, q statespace\n",
    "#f[-1]+=0.1\n",
    "print(f)\n",
    "dig=[]\n",
    "for i in test:\n",
    "    dig.append(np.digitize(i, f)-1)\n",
    "print(dig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
