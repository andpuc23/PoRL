{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.train_env import Electric_Car\n",
    "from models.baseline import BaselineModel\n",
    "from models.baseline2 import BaselineModel2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models.tabular_qlearning import TabularQLearning\n",
    "\n",
    "from envs.feature_engineering import DataHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DataHelper()\n",
    "\n",
    "def learn(env, model):\n",
    "    states, rewards, infos = [], [], []\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "    while(terminated == False and truncated == False):\n",
    "        action = model.predict(env)\n",
    "        obs, reward, termination, truncation, info = env.step(action)\n",
    "        new_obs = dh.process_data(obs)\n",
    "\n",
    "        states.append(new_obs)\n",
    "        rewards.append(reward)\n",
    "        terminated = termination\n",
    "        truncated = truncation\n",
    "        infos.append(info)\n",
    "\n",
    "    return states, rewards, terminated, truncated, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins_actions [-1.         -0.89473684 -0.78947368 -0.68421053 -0.57894737 -0.47368421\n",
      " -0.36842105 -0.26315789 -0.15789474 -0.05263158  0.05263158  0.15789474\n",
      "  0.26315789  0.36842105  0.47368421  0.57894737  0.68421053  0.78947368\n",
      "  0.89473684  1.        ]\n",
      "bins_battery [ 0.          2.63157895  5.26315789  7.89473684 10.52631579 13.15789474\n",
      " 15.78947368 18.42105263 21.05263158 23.68421053 26.31578947 28.94736842\n",
      " 31.57894737 34.21052632 36.84210526 39.47368421 42.10526316 44.73684211\n",
      " 47.36842105 50.        ]\n",
      "bins_price [   0.          131.57894737  263.15789474  394.73684211  526.31578947\n",
      "  657.89473684  789.47368421  921.05263158 1052.63157895 1184.21052632\n",
      " 1315.78947368 1447.36842105 1578.94736842 1710.52631579 1842.10526316\n",
      " 1973.68421053 2105.26315789 2236.84210526 2368.42105263 2500.        ]\n",
      "state before discr [2.500e+01 2.431e+01 1.000e+00 0.000e+00 1.000e+00 1.000e+00 2.007e+03\n",
      " 1.000e+00]\n",
      "whole state [   9    0    1    0    1    1 2007    1]\n",
      "part of state [9 0 1 0 1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0    2    0    1    1 2007    1]\n",
      "part of state [0 0 2 0 1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0    3    0    1    1 2007    1]\n",
      "part of state [0 0 3 0 1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0    4    0    1    1 2007    1]\n",
      "part of state [0 0 4 0 1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0    5    0    1    1 2007    1]\n",
      "part of state [0 0 5 0 1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0    6    0    1    1 2007    1]\n",
      "part of state [0 0 6 0 1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0    7    0    1    1 2007    1]\n",
      "part of state [0 0 7 0 1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   7    0    8    0    1    1 2007    1]\n",
      "part of state [7 0 8 0 1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0    9    0    1    1 2007    1]\n",
      "part of state [0 0 9 0 1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0   10    0    1    1 2007    1]\n",
      "part of state [ 0  0 10  0  1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0   11    0    1    1 2007    1]\n",
      "part of state [ 0  0 11  0  1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "whole state [   0    0   12    0    1    1 2007    1]\n",
      "part of state [ 0  0 12  0  1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0   13    0    1    1 2007    1]\n",
      "part of state [ 0  0 13  0  1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0   14    0    1    1 2007    1]\n",
      "part of state [ 0  0 14  0  1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0   15    0    1    1 2007    1]\n",
      "part of state [ 0  0 15  0  1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0   16    0    1    1 2007    1]\n",
      "part of state [ 0  0 16  0  1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n",
      "whole state [   0    0   17    0    1    1 2007    1]\n",
      "part of state [ 0  0 17  0  1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "whole state [   0    0   18    0    1    1 2007    1]\n",
      "part of state [ 0  0 18  0  1]\n",
      "shape q (19, 19, 24, 7, 12, 19)\n",
      "shape action bins (20,)\n",
      "bin -1.0 -1.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 19 is out of bounds for axis 0 with size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-75286b572356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularQLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/project RL/PoRL/models/tabular_qlearning.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, simulations, learning_rate, epsilon, epsilon_decay, adaptive_epsilon, adapting_learning_rate)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscretize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mQ_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_vars_qtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mQ_target\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_vars_qtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_vars_qtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_vars_qtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 19 is out of bounds for axis 0 with size 19"
     ]
    }
   ],
   "source": [
    "data_path = 'data/train.xlsx'\n",
    "simulations = 10\n",
    "learning_rate = 0.5\n",
    "model = TabularQLearning(data_path)\n",
    "model.train(simulations, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
